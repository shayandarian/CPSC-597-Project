{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Oix3Lyp3baim"
      },
      "outputs": [],
      "source": [
        "#Library Imports\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import random\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "from sklearn.neighbors import NearestNeighbors"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "DATA PREPROCESSING\n",
        "\n"
      ],
      "metadata": {
        "id": "jl93JJxF5YNK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Load the datasets\n",
        "datasetMovies = pd.read_csv('movies.csv', sep='::', engine='python', header=None, names=['MovieID', 'Title', 'Genres']).dropna()\n",
        "datasetRatings = pd.read_csv('ratings.csv', sep='::', engine='python', header=None, names=['UserID', 'MovieID', 'Rating', 'Timestamp']).dropna()\n",
        "datasetUsers = pd.read_csv('users.csv', sep='::', engine='python', header=None, names=['UserID', 'Gender', 'Age', 'Occupation', 'Zip-code']).dropna()"
      ],
      "metadata": {
        "id": "qAtMtuM0bvnG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Movie information is in the file \"movies.csv\" and is originally in the following format:\n",
        "\n",
        "MovieID::Title::Genres\n",
        "\n",
        "- Titles are identical to titles provided by the IMDB (including\n",
        "year of release)\n",
        "- Genres are pipe-separated and are selected from the following genres:\n",
        "\n",
        "\t* Action\n",
        "\t* Adventure\n",
        "\t* Animation\n",
        "\t* Children's\n",
        "\t* Comedy\n",
        "\t* Crime\n",
        "\t* Documentary\n",
        "\t* Drama\n",
        "\t* Fantasy\n",
        "\t* Film-Noir\n",
        "\t* Horror\n",
        "\t* Musical\n",
        "\t* Mystery\n",
        "\t* Romance\n",
        "\t* Sci-Fi\n",
        "\t* Thriller\n",
        "\t* War\n",
        "\t* Western\n",
        "\n",
        "- Some MovieIDs do not correspond to a movie due to accidental duplicate\n",
        "entries and/or test entries\n",
        "- Movies are mostly entered by hand, so errors and inconsistencies may exist"
      ],
      "metadata": {
        "id": "51hC-jrzT9-v"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"movies.csv shape:\", datasetMovies.shape)\n",
        "datasetMovies.head() #display the first 5 rows of movies.csv"
      ],
      "metadata": {
        "id": "rvY4GyoobyEy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "All ratings are contained in the file \"ratings.csv\" and are originally in the\n",
        "following format:\n",
        "\n",
        "UserID::MovieID::Rating::Timestamp\n",
        "\n",
        "- UserIDs range between 1 and 6040\n",
        "- MovieIDs range between 1 and 3952\n",
        "- Ratings are made on a 5-star scale (whole-star ratings only)\n",
        "- Timestamp is represented in seconds since the epoch as returned by time(2)\n",
        "- Each user has at least 20 ratings"
      ],
      "metadata": {
        "id": "8FUS-ZanUPAG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"ratings.csv shape:\", datasetRatings.shape)\n",
        "datasetRatings.head() #display the first 5 rows of ratings.csv"
      ],
      "metadata": {
        "id": "fIFHFrSJb1l_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "User information is in the file \"users.csv\" and is originally in the following format:\n",
        "\n",
        "UserID::Gender::Age::Occupation::Zip-code\n",
        "\n",
        "All demographic information is provided voluntarily by the users and is\n",
        "not checked for accuracy.  Only users who have provided some demographic\n",
        "information are included in this data set.\n",
        "\n",
        "- Gender is denoted by a \"M\" for male and \"F\" for female\n",
        "- Age is chosen from the following ranges:\n",
        "\n",
        "\t*  1:  \"Under 18\"\n",
        "\t* 18:  \"18-24\"\n",
        "\t* 25:  \"25-34\"\n",
        "\t* 35:  \"35-44\"\n",
        "\t* 45:  \"45-49\"\n",
        "\t* 50:  \"50-55\"\n",
        "\t* 56:  \"56+\"\n",
        "\n",
        "- Occupation is chosen from the following choices:\n",
        "\n",
        "\t*  0:  \"other\" or not specified\n",
        "\t*  1:  \"academic/educator\"\n",
        "\t*  2:  \"artist\"\n",
        "\t*  3:  \"clerical/admin\"\n",
        "\t*  4:  \"college/grad student\"\n",
        "\t*  5:  \"customer service\"\n",
        "\t*  6:  \"doctor/health care\"\n",
        "\t*  7:  \"executive/managerial\"\n",
        "\t*  8:  \"farmer\"\n",
        "\t*  9:  \"homemaker\"\n",
        "\t* 10:  \"K-12 student\"\n",
        "\t* 11:  \"lawyer\"\n",
        "\t* 12:  \"programmer\"\n",
        "\t* 13:  \"retired\"\n",
        "\t* 14:  \"sales/marketing\"\n",
        "\t* 15:  \"scientist\"\n",
        "\t* 16:  \"self-employed\"\n",
        "\t* 17:  \"technician/engineer\"\n",
        "\t* 18:  \"tradesman/craftsman\"\n",
        "\t* 19:  \"unemployed\"\n",
        "\t* 20:  \"writer\""
      ],
      "metadata": {
        "id": "X51PJ2AJUWuV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"users.csv shape:\", datasetUsers.shape)\n",
        "datasetUsers.head() #display the first 5 rows of users.csv"
      ],
      "metadata": {
        "id": "i0a6qQbPTm8S"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "datasetMovies['MovieID'] = datasetMovies['MovieID'].astype('int32')\n",
        "datasetMovies['Title'] = datasetMovies['Title'].astype('str')\n",
        "datasetMovies['Genres'] = datasetMovies['Genres'].astype('str')\n",
        "print(\"movies.csv shape:\", datasetMovies.shape)\n",
        "datasetMovies.head() #display the first 5 rows of movies.csv"
      ],
      "metadata": {
        "id": "eFNehuMWbzqd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "datasetRatings = datasetRatings.drop(columns = 'Timestamp')\n",
        "datasetRatings['UserID'] = datasetRatings['UserID'].astype('int32')\n",
        "datasetRatings['MovieID'] = datasetRatings['MovieID'].astype('int32')\n",
        "datasetRatings['Rating'] = datasetRatings['Rating'].astype('float32')\n",
        "print(\"ratings.csv shape:\", datasetRatings.shape)\n",
        "datasetRatings.head() #display the first 5 rows of ratings.csv"
      ],
      "metadata": {
        "id": "0kxVQxlOb3GI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "datasetUsers = datasetUsers.drop(columns = 'Zip-code')\n",
        "datasetUsers['UserID'] = datasetUsers['UserID'].astype('int32')\n",
        "datasetUsers['Gender'] = datasetUsers['Gender'].astype('str')\n",
        "datasetUsers['Age'] = datasetUsers['Age'].astype('int32')\n",
        "datasetUsers['Occupation'] = datasetUsers['Occupation'].astype('int32')\n",
        "print(\"users.csv shape:\", datasetUsers.shape)\n",
        "datasetUsers.head() #display the first 5 rows of users.csv"
      ],
      "metadata": {
        "id": "kSSb51Nu82Wj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Merge the movie and ratings datasets\n",
        "#Create a new dataset containing the entries of both movies.csv and ratings.csv\n",
        "movieRatingsMerged = pd.merge(datasetMovies, datasetRatings, on = 'MovieID').dropna()\n",
        "print(\"merged dataset shape:\", movieRatingsMerged.shape)\n",
        "movieRatingsMerged.head() #display the first 5 rows of the merged dataset"
      ],
      "metadata": {
        "id": "J6OucTxTb4r-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Merge the movieRatingsMerged dataframe with the users dataset\n",
        "datasetMerged = pd.merge(movieRatingsMerged, datasetUsers, on = 'UserID').dropna()\n",
        "print(\"final merged dataset shape:\", datasetMerged.shape)\n",
        "datasetMerged.head() #diplay the first 5 rows of the final merged dataset"
      ],
      "metadata": {
        "id": "Pz0bado89TnZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Dataset size reduction"
      ],
      "metadata": {
        "id": "_THbpfUWmt4V"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Need to reduce the size of the dataset - kernel will keep crashing otherwise\n",
        "#Lets only include reviews from active users\n",
        "user_count = datasetMerged['UserID'].value_counts() #counts unique users\n",
        "active_users = user_count[user_count >= 700].index\n",
        "datasetReduced = datasetMerged[datasetMerged['UserID'].isin(active_users)]\n",
        "datasetReduced = datasetReduced.dropna()\n",
        "print(\"reduced dataset shape:\", datasetReduced.shape)\n",
        "datasetReduced.head()"
      ],
      "metadata": {
        "id": "ROSbGqx1b6QN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Create a mapping for movieId to title (To print titles in final output)"
      ],
      "metadata": {
        "id": "R0v24fUUnhUJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Create a mapping for movieId to title (To print titles in later outputs)\n",
        "movie_mapping = dict(zip(datasetMovies['MovieID'], datasetMovies['Title']))\n",
        "print(movie_mapping)"
      ],
      "metadata": {
        "id": "eNbnqPQBb9g0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "CONTENT-BASED FILTERING"
      ],
      "metadata": {
        "id": "ODcfIRntxO7y"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Working with Genres"
      ],
      "metadata": {
        "id": "96BYv9lA5D-o"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Goal - Create one hot encoding for Genres (WORKING WITH datasetMovies ONLY in order to avoid duplicate movies from merged dataset)\n",
        "#Split the Genre categories into separate items\n",
        "datasetMovies['Genres'] = datasetMovies['Genres'].str.replace('|', ' ')\n",
        "print(\"final merged dataset shape:\", datasetMovies.shape)\n",
        "datasetMovies.head() #display the first 5 rows of the final merged dataset"
      ],
      "metadata": {
        "id": "rou0_6sFUo_X"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "TD-IDF Vectorization"
      ],
      "metadata": {
        "id": "-0SF3iQJt5kN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#TF-IDF Vectorization\n",
        "#Convert genres to TF-IDF vectors\n",
        "tfidf = TfidfVectorizer(token_pattern=r\"(?u)\\b\\w+\\b\", lowercase=False, use_idf=False)\n",
        "tfidf_matrix = tfidf.fit_transform(datasetMovies['Genres'])\n",
        "print(pd.DataFrame(tfidf_matrix.toarray(), index=datasetMovies['Title'], columns=tfidf.get_feature_names_out()))"
      ],
      "metadata": {
        "id": "KgQfvDX5m9Y_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Compute the cosine similarity\n",
        "cosine_sim = cosine_similarity(tfidf_matrix)"
      ],
      "metadata": {
        "id": "tAdzTs7nSlKv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Content-Based Filtering\n",
        "def content_based_model(user_id, datasetMovies, datasetReduced, cosine_sim, num_reviews, top_n=10):\n",
        "  if num_reviews == 0:\n",
        "    choice = input(\"You haven't reviewed any movies yet. Would you like to search for a movie to watch? (yes/no): \").strip().lower()\n",
        "    if choice == 'yes':\n",
        "      #Step 1: Ask the user for the movie that they would like to watch\n",
        "      movie_title = input(f\"Enter the name of the movie that you'd like to watch: \")\n",
        "      #Ensure the movie exists in the dataset\n",
        "      if movie_title not in datasetMovies['Title'].values:\n",
        "          print(\"❌ Movie not found in the dataset.\")\n",
        "          return datasetReduced\n",
        "\n",
        "      #Step 2: Ask the user to rate this movie\n",
        "      try:\n",
        "          rating = float(input(f\"Enter your rating for '{movie_title}' (0.0-5.0): \"))\n",
        "          if rating < 0 or rating > 5:\n",
        "              print(\"❌ Invalid rating. Please enter a number between 0.0 and 5.0.\")\n",
        "              return datasetReduced\n",
        "\n",
        "          #Retrieve MovieID for the selected movie\n",
        "          movie_id = datasetReduced.loc[datasetReduced['Title'] == movie_title, 'MovieID'].values[0]\n",
        "\n",
        "          #Step 2.1: Check if the user has already rated the movie\n",
        "          existing_rating = datasetReduced[(datasetReduced['UserID'] == user_id) & (datasetReduced['MovieID'] == movie_id)]\n",
        "\n",
        "          if not existing_rating.empty:\n",
        "              #User has already rated this movie, so we update the rating\n",
        "              datasetReduced.loc[(datasetReduced['UserID'] == user_id) & (datasetReduced['MovieID'] == movie_id), 'Rating'] = rating\n",
        "              print(f\"\\n✅ Your rating for '{movie_title}' has been updated to {rating}/5.0\")\n",
        "          else:\n",
        "              #User has not rated the movie yet, so we append a new entry\n",
        "              new_entry = pd.DataFrame({\n",
        "                  'UserID': [user_id],\n",
        "                  'MovieID': [movie_id],\n",
        "                  'Title': [movie_title],\n",
        "                  'Genres': [datasetReduced[datasetReduced['Title'] == movie_title]['Genres'].values[0]],\n",
        "                  'Rating': [rating]\n",
        "              })\n",
        "              datasetReduced = pd.concat([datasetReduced, new_entry], ignore_index=True)\n",
        "              print(f\"\\n✅ Your rating has been recorded successfully!\\nUser {user_id} rated '{movie_title}' with a score of {rating}/5.0\")\n",
        "\n",
        "      except ValueError:\n",
        "          print(\"❌ Invalid input. Please enter a number.\")\n",
        "\n",
        "    elif choice == 'no':\n",
        "        print(\"Recommending a random movie for you...\")\n",
        "        all_titles = set(datasetMovies['Title'].values)\n",
        "        eligible_titles = list(all_titles)\n",
        "        if eligible_titles: #Safety check\n",
        "            movie_title = random.choice(eligible_titles)\n",
        "            print(f\"\\nYour first recommended movie is: {movie_title} (Random Pick!)\")\n",
        "\n",
        "        #Step 2: Ask the user to rate this movie\n",
        "        try:\n",
        "            rating = float(input(f\"Enter your rating for '{movie_title}' (0.0-5.0): \"))\n",
        "            if rating < 0 or rating > 5:\n",
        "                print(\"❌ Invalid rating. Please enter a number between 0.0 and 5.0.\")\n",
        "                return datasetReduced\n",
        "\n",
        "            #Retrieve MovieID for the selected movie\n",
        "            movie_id = datasetReduced.loc[datasetReduced['Title'] == movie_title, 'MovieID'].values[0]\n",
        "\n",
        "            #Step 2.1: Check if the user has already rated the movie\n",
        "            existing_rating = datasetReduced[(datasetReduced['UserID'] == user_id) & (datasetReduced['MovieID'] == movie_id)]\n",
        "\n",
        "            if not existing_rating.empty:\n",
        "                #User has already rated this movie, so we update the rating\n",
        "                datasetReduced.loc[(datasetReduced['UserID'] == user_id) & (datasetReduced['MovieID'] == movie_id), 'Rating'] = rating\n",
        "                print(f\"\\n✅ Your rating for '{movie_title}' has been updated to {rating}/5.0\")\n",
        "            else:\n",
        "                #User has not rated the movie yet, so we append a new entry\n",
        "                new_entry = pd.DataFrame({\n",
        "                    'UserID': [user_id],\n",
        "                    'MovieID': [movie_id],\n",
        "                    'Title': [movie_title],\n",
        "                    'Genres': [datasetReduced[datasetReduced['Title'] == movie_title]['Genres'].values[0]],\n",
        "                    'Rating': [rating]\n",
        "                })\n",
        "                datasetReduced = pd.concat([datasetReduced, new_entry], ignore_index=True)\n",
        "                print(f\"\\n✅ Your rating has been recorded successfully!\\nUser {user_id} rated '{movie_title}' with a score of {rating}/5.0\")\n",
        "\n",
        "        except ValueError:\n",
        "            print(\"❌ Invalid input. Please enter a number.\")\n",
        "\n",
        "    else:\n",
        "      print(\"Invalid input. Please try again.\")\n",
        "      return datasetReduced\n",
        "  else:\n",
        "    #Step 1: Ask the user for the movie that they would like to watch\n",
        "    movie_title = input(f\"Enter the name of the movie that you'd like to watch: \")\n",
        "    #Ensure the movie exists in the dataset\n",
        "    if movie_title not in datasetMovies['Title'].values:\n",
        "        print(\"❌ Movie not found in the dataset.\")\n",
        "        return datasetReduced\n",
        "\n",
        "    #Step 2: Ask the user to rate this movie\n",
        "    try:\n",
        "        rating = float(input(f\"Enter your rating for '{movie_title}' (0.0-5.0): \"))\n",
        "        if rating < 0 or rating > 5:\n",
        "            print(\"❌ Invalid rating. Please enter a number between 0.0 and 5.0.\")\n",
        "            return datasetReduced\n",
        "\n",
        "        #Retrieve MovieID for the selected movie\n",
        "        movie_id = datasetReduced.loc[datasetReduced['Title'] == movie_title, 'MovieID'].values[0]\n",
        "\n",
        "        #Step 2.1: Check if the user has already rated the movie\n",
        "        existing_rating = datasetReduced[(datasetReduced['UserID'] == user_id) & (datasetReduced['MovieID'] == movie_id)]\n",
        "\n",
        "        if not existing_rating.empty:\n",
        "            #User has already rated this movie, so we update the rating\n",
        "            datasetReduced.loc[(datasetReduced['UserID'] == user_id) & (datasetReduced['MovieID'] == movie_id), 'Rating'] = rating\n",
        "            print(f\"\\n✅ Your rating for '{movie_title}' has been updated to {rating}/5.0\")\n",
        "        else:\n",
        "            #User has not rated the movie yet, so we append a new entry\n",
        "            new_entry = pd.DataFrame({\n",
        "                'UserID': [user_id],\n",
        "                'MovieID': [movie_id],\n",
        "                'Title': [movie_title],\n",
        "                'Genres': [datasetReduced[datasetReduced['Title'] == movie_title]['Genres'].values[0]],\n",
        "                'Rating': [rating]\n",
        "            })\n",
        "            datasetReduced = pd.concat([datasetReduced, new_entry], ignore_index=True)\n",
        "            print(f\"\\n✅ Your rating has been recorded successfully!\\nUser {user_id} rated '{movie_title}' with a score of {rating}/5.0\")\n",
        "\n",
        "    except ValueError:\n",
        "        print(\"❌ Invalid input. Please enter a number.\")\n",
        "\n",
        "  #Step 3: Get recommendations based on content similarity\n",
        "  #Get the index of the movie\n",
        "  idx = datasetMovies[datasetMovies['Title'] == movie_title].index[0]\n",
        "  #Compute similarity scores\n",
        "  sim_scores = list(enumerate(cosine_sim[idx]))\n",
        "  #Sort movies by similarity score (Descending)\n",
        "  sim_scores = sorted(sim_scores, key=lambda x: x[1], reverse=True)\n",
        "  #Exclude the selected movie from recommendations\n",
        "  sim_scores = [s for s in sim_scores if datasetMovies.iloc[s[0]]['Title'] != movie_title]\n",
        "  #Take only the top N recommendations\n",
        "  sim_scores = sim_scores[:top_n]\n",
        "  #Get the list of recommended movies\n",
        "  recommended_movies = [datasetMovies.iloc[i[0]]['Title'] for i in sim_scores]\n",
        "  #Get the similarity scores of each recommended movie\n",
        "  similarity_scores = [i[1] for i in sim_scores]\n",
        "\n",
        "  #Display recommendations to the user\n",
        "  print(\"\\nHere are the top {0} recommendations for {1}:\".format(top_n, movie_title))\n",
        "  for i, (movie, score) in enumerate(zip(recommended_movies, similarity_scores), start=1):\n",
        "      print(f\"{i}. {movie}: {score:.4f}\")\n",
        "\n",
        "  #🎲 10% chance to show an extra random recommendation\n",
        "  if random.random() < 0.1:\n",
        "      all_titles = set(datasetMovies['Title'].values)\n",
        "      excluded_titles = set(recommended_movies + [movie_title])\n",
        "      eligible_titles = list(all_titles - excluded_titles)\n",
        "      if eligible_titles:  #Safety check\n",
        "          bonus_movie = random.choice(eligible_titles)\n",
        "          print(f\"\\n🎲 Bonus Recommendation (Random Pick): {bonus_movie}\")\n",
        "\n",
        "  return datasetReduced  #Return updated dataframe"
      ],
      "metadata": {
        "id": "6YojMAiyMf1X"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "COLLABORATIVE-BASED FILTERING"
      ],
      "metadata": {
        "id": "N65nchTq5dh6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def collaborative_based_model(user_id, datasetReduced, movie_mapping, n_neighbors=10):\n",
        "    #User-Item Interaction Matrix\n",
        "    user_item_matrix = datasetReduced.pivot(index='UserID', columns='MovieID', values='Rating')\n",
        "    mean_user_rating = np.mean(user_item_matrix, axis=1)\n",
        "    normalized_user_item_matrix = user_item_matrix.sub(mean_user_rating, axis=0).fillna(0)\n",
        "\n",
        "    #Fit KNN model\n",
        "    model_knn = NearestNeighbors(metric='cosine', algorithm='brute')\n",
        "    model_knn.fit(normalized_user_item_matrix)\n",
        "\n",
        "    if user_id not in normalized_user_item_matrix.index:\n",
        "        print(f\"User {user_id} is not found in the dataset.\")\n",
        "        return []\n",
        "\n",
        "    input_vector = normalized_user_item_matrix.loc[user_id].values.reshape(1, -1)\n",
        "    distances, indices = model_knn.kneighbors(input_vector, n_neighbors=n_neighbors + 1)\n",
        "    similar_user_ids = normalized_user_item_matrix.index[indices.flatten()[1:]]\n",
        "\n",
        "    print(f\"Most similar users to User {user_id} based on cosine similarity:\")\n",
        "    for i in range(1, len(distances.flatten())):\n",
        "        print(f\"User ID: {similar_user_ids[i-1]}, Similarity Distance: {distances.flatten()[i]:.4f}\")\n",
        "\n",
        "    recommended_movies = datasetReduced[datasetReduced['UserID'].isin(similar_user_ids)]\n",
        "    top_movies = recommended_movies.groupby('MovieID')['Rating'].mean().sort_values(ascending=False)\n",
        "\n",
        "    already_rated = datasetReduced[datasetReduced['UserID'] == user_id]['MovieID'].values\n",
        "    top_unseen_movies = top_movies.loc[~top_movies.index.isin(already_rated)].head(10)\n",
        "\n",
        "    recommendations = [(movie_mapping.get(movie_id, \"Unknown Movie\"), rating, movie_id) for movie_id, rating in top_unseen_movies.items()]\n",
        "\n",
        "    print(f\"\\nRecommendations for User {user_id} based on similar users:\\n\")\n",
        "    for i, (title, rating, _) in enumerate(recommendations, start=1):\n",
        "        print(f\"{i}: {title} (Predicted Rating: {rating:.2f})\")\n",
        "\n",
        "    #🎲 10% chance of showing a bonus recommendation\n",
        "    bonus_movie = None\n",
        "    if random.random() <= 0.1:\n",
        "        all_movie_ids = datasetReduced['MovieID'].unique()\n",
        "        unrated_movie_ids = list(set(all_movie_ids) - set(already_rated))\n",
        "        if unrated_movie_ids:\n",
        "            bonus_movie_id = random.choice(unrated_movie_ids)\n",
        "            bonus_title = movie_mapping.get(bonus_movie_id, \"Unknown Movie\")\n",
        "            bonus_movie = (bonus_title, bonus_movie_id)\n",
        "            print(f\"\\n🎲 Bonus Recommendation (Random Pick): {bonus_title}\")\n",
        "            print(f\"{len(recommendations)+1}: {bonus_title} (Bonus)\")\n",
        "\n",
        "    #Let the user choose which movie to rate\n",
        "    total_choices = len(recommendations) + (1 if bonus_movie else 0)\n",
        "    movie_choice = input(f\"\\nSelect a movie to watch by entering its number (1-{total_choices}): \")\n",
        "\n",
        "    try:\n",
        "        movie_choice = int(movie_choice) - 1\n",
        "        if movie_choice < 0 or movie_choice >= total_choices:\n",
        "            print(\"❌ Invalid choice. Please select a valid number.\")\n",
        "            return datasetReduced\n",
        "\n",
        "        #Determine if it's a bonus movie\n",
        "        if bonus_movie and movie_choice == len(recommendations):\n",
        "            selected_movie_title, movie_id = bonus_movie\n",
        "        else:\n",
        "            selected_movie_title, _, movie_id = recommendations[movie_choice]\n",
        "\n",
        "        #Prompt for rating\n",
        "        rating = float(input(f\"Enter your rating for '{selected_movie_title}' (0.0 - 5.0): \"))\n",
        "        if rating < 0 or rating > 5:\n",
        "            print(\"❌ Invalid rating. Please enter a number between 0.0 and 5.0.\")\n",
        "            return datasetReduced\n",
        "\n",
        "        #🔁 Update rating if exists, otherwise append\n",
        "        mask = (datasetReduced['UserID'] == user_id) & (datasetReduced['MovieID'] == movie_id)\n",
        "        if datasetReduced[mask].empty:\n",
        "            new_entry = pd.DataFrame({\n",
        "                'UserID': [user_id],\n",
        "                'MovieID': [movie_id],\n",
        "                'Title': [selected_movie_title],\n",
        "                'Genres': [datasetReduced[datasetReduced['MovieID'] == movie_id]['Genres'].values[0]],\n",
        "                'Rating': [rating]\n",
        "            })\n",
        "            datasetReduced = pd.concat([datasetReduced, new_entry], ignore_index=True)\n",
        "        else:\n",
        "            datasetReduced.loc[mask, 'Rating'] = rating\n",
        "\n",
        "        print(f\"\\n✅ Your rating has been recorded successfully!\\nUser {user_id} rated '{selected_movie_title}' with a score of {rating}/5.0\")\n",
        "\n",
        "    except ValueError:\n",
        "        print(\"❌ Invalid input. Please enter a valid number.\")\n",
        "\n",
        "    return datasetReduced #Return updated dataframe"
      ],
      "metadata": {
        "id": "xY52mXjUe5mQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "USER INTERFACE"
      ],
      "metadata": {
        "id": "RsJy8JmLjyTI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def get_recommendations_for_user(user_id, datasetReduced, content_based_model, collaborative_based_model):\n",
        "  #Check how many reviews the user has submitted\n",
        "  user_reviews = datasetReduced[datasetReduced['UserID'] == user_id]\n",
        "  num_reviews = len(user_reviews)\n",
        "\n",
        "  if num_reviews < 5:\n",
        "      print(\"Using Content-Based Filtering...\")\n",
        "      datasetReduced = content_based_model(user_id, datasetMovies, datasetReduced, cosine_sim, num_reviews)\n",
        "      return datasetReduced\n",
        "\n",
        "  else:\n",
        "      print(\"Using Collaborative-Based Filtering...\")\n",
        "      datasetReduced = collaborative_based_model(user_id, datasetReduced, movie_mapping)\n",
        "      return datasetReduced\n"
      ],
      "metadata": {
        "id": "9j8hJY68iDeX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Asks for your user ID, if you don't have one, it creates a new user ID for you\n",
        "#Ask the user for their user ID\n",
        "user_id = input(\"Enter your User ID (or press Enter if new): \").strip()\n",
        "\n",
        "#Check if the user ID exists in the dataframe\n",
        "if user_id in datasetReduced['UserID'].astype(str).values:\n",
        "    print(f\"✅ Welcome back, User {user_id}!\")\n",
        "else:\n",
        "    #Generate a new user ID\n",
        "    new_user_id = datasetReduced['UserID'].max() + 1\n",
        "    user_id = np.int32(new_user_id)\n",
        "    print(f\"🆕 New user detected. Assigning User ID: {user_id}\")"
      ],
      "metadata": {
        "id": "SjSLGj713Yln"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "GET RECOMMENDATIONS"
      ],
      "metadata": {
        "id": "dZFlY5BNkcpm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "datasetReduced = get_recommendations_for_user(user_id, datasetReduced, content_based_model, collaborative_based_model)"
      ],
      "metadata": {
        "id": "sy9B0zh_6Ft0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "TESTING AND DEBUGGING"
      ],
      "metadata": {
        "id": "XqiPQ2Ysjt_r"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#For testing\n",
        "print(datasetReduced.tail(10))  #View the last 10 rows\n",
        "#print(datasetReduced[datasetReduced[\"UserID\"] == user_id]) #Check to see the movies rated by the current user\n",
        "#print(datasetReduced[datasetReduced[\"Title\"] == \"Toy Story (1995)\"]) #Check to see if a specific movie was added\n",
        "#print(datasetReduced.info())  #Shows column types and number of entries"
      ],
      "metadata": {
        "id": "sacuzVJIpIzb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#For Testing\n",
        "#Lookup User Ratings by UserID\n",
        "def get_user_ratings(user_id, datasetReduced):\n",
        "    #Filter the dataset to get all ratings submitted by the user with the given UserID\n",
        "    user_ratings = datasetReduced[datasetReduced['UserID'] == user_id]\n",
        "\n",
        "    #Return the user ratings, which will include MovieID, Rating, and possibly other columns\n",
        "    return user_ratings[['MovieID', 'Rating']]"
      ],
      "metadata": {
        "id": "ZiilSqJt_MB3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#For Testing (same as above but returns Titles instead of Movie IDs)\n",
        "def get_user_ratings_with_titles(user_id, datasetReduced, movie_mapping):\n",
        "    #Filter the dataset to get all ratings submitted by the user with the given UserID\n",
        "    user_ratings = datasetReduced[datasetReduced['UserID'] == user_id]\n",
        "\n",
        "    #Debugging: Check if the UserID exists in the dataset\n",
        "    print(f\"UserID {user_id} found in dataset: {not user_ratings.empty}\")\n",
        "\n",
        "    #Map the MovieID to movie titles using the movie_mapping dictionary\n",
        "    user_ratings['Title'] = user_ratings['MovieID'].map(movie_mapping)\n",
        "\n",
        "    #Debugging: Check if any MovieID couldn't be mapped\n",
        "    print(f\"Number of ratings with valid titles: {user_ratings['Title'].notna().sum()}\")\n",
        "\n",
        "    #Return the user ratings with movie titles instead of MovieID\n",
        "    return user_ratings[['Title', 'Rating']]"
      ],
      "metadata": {
        "id": "UhazB5yxA2xE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#For Testing the above 2 functions\n",
        "user_id = 6037\n",
        "#user_id = 4510  #Replace with the UserID that you want to look up\n",
        "#user_ratings = get_user_ratings(user_id, datasetReduced)\n",
        "user_ratings = get_user_ratings_with_titles(user_id, datasetReduced, movie_mapping)\n",
        "#Print the user's ratings for each movie\n",
        "print(user_ratings)"
      ],
      "metadata": {
        "id": "4YKR7pq9_NOM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#For Testing\n",
        "#Looking up all the common rated movies between our user and one of his similar neighbors\n",
        "def get_common_rated_movies(target_user_id, lookup_user_id, datasetReduced, movie_mapping):\n",
        "    #Get the ratings for both the target user and the lookup user\n",
        "    target_user_ratings = datasetReduced[datasetReduced['UserID'] == target_user_id].copy()\n",
        "    lookup_user_ratings = datasetReduced[datasetReduced['UserID'] == lookup_user_id].copy()\n",
        "\n",
        "    #Perform an inner join to find movies that both users have rated\n",
        "    common_movies = pd.merge(target_user_ratings[['MovieID', 'Rating']],\n",
        "                             lookup_user_ratings[['MovieID', 'Rating']],\n",
        "                             on='MovieID', how='inner', suffixes=('_target', '_lookup'))\n",
        "\n",
        "    #Map the MovieID to movie titles using the movie_mapping dictionary\n",
        "    common_movies['Title'] = common_movies['MovieID'].map(movie_mapping)\n",
        "\n",
        "    #Rename the columns for clarity\n",
        "    common_movies = common_movies.rename(columns={\n",
        "        'Rating_target': 'Your_Rating',\n",
        "        'Rating_lookup': 'Similar_Users_Rating'\n",
        "    })\n",
        "\n",
        "    #Return the rows where both users have rated the same movie, showing the title instead of MovieID\n",
        "    return common_movies[['Title', 'Your_Rating', 'Similar_Users_Rating']]"
      ],
      "metadata": {
        "id": "lN_iLa6IBqyc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#For Testing the above function\n",
        "target_user_id = 6037  #Replace with the target UserID\n",
        "lookup_user_id = 4725  #Replace with the UserID that you are looking up\n",
        "\n",
        "common_movies = get_common_rated_movies(target_user_id, lookup_user_id, datasetReduced, movie_mapping)\n",
        "\n",
        "#Print the common movies with their ratings\n",
        "print(common_movies)"
      ],
      "metadata": {
        "id": "z6p2Q1PVB-oh"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}